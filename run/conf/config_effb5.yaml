# ---------- Overriding hydra default configs ----------
hydra:
  job:
    name: happy_whale_effb5
  run:
    dir: ${out_dir}

# ---------- Default settings ----------
defaults:
  - dataset: happy_whale
  - optimizer: adamw  # 建议用 adamw 稳定性更好
  - scheduler: cosine_annealing

  # For hydra colorlog
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog


# ---------- Other configs ----------

#====
# Preprocessing
#====
preprocessing:
  h_resize_to: 512  # 你提到的鱼鳍/全身训练分辨率
  w_resize_to: 512
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]


#====
# Model
#====
model:
  restore_path: ${test_model}

  base_model: tf_efficientnet_b5  # 改为 effb5
  backbone_class: null
  freeze_backbone: false

  head: ${head}
  output_dim: ${dataset.num_classes}
  output_dim_species: ${dataset.num_species_classes}
  pool: ${pool}
  use_bn: true
  embedding_size: 512 # 统一 embedding 维度方便后续 concat
  in_chans: 3
  backbone2: false
  species_embedding_size: -1

pool:
  type: gem
  p: 3
  p_trainable: false

#====
# Model head
#====
head:
  type: adaptive_arcface
  m: 0.2
  s: 20.0
  k: 3
  k_species: 3
  head_species: true
  s_species: 30
  use_penalty: true
  margin_coef_id: 0.27126
  margin_power_id: -0.364399
  margin_cons_id: 0.05
  margin_coef_species: 0.226253
  margin_power_species: -0.720133
  margin_cons_species: 0.05
  init: uniform
  init_species: uniform


#====
# Forwarder
#====
forwarder:
  max_epochs: ${training.epoch}
  head: ${head}
  backbone2: ${model.backbone2}
  species_embedding_size: ${model.species_embedding_size}

  tta:
    flip_h: true
    rot90: false
    rot180: false


#====
# Dataset
#====
dataset:
  type: happy_whale
  num_classes: 15587


#====
# Data augmentation (添加锐化和灰度缩放)
#====
augmentation:
  use_aug: true
  rotate: 15
  translate: 0.25
  shear: 3
  p_affine: 0.5
  crop_scale: 0.9
  crop_l: 0.75
  crop_r: 1.3333333333333333
  p_gray: 0.2 # 增加灰度概率以关注纹理
  p_blur: 0.05
  p_noise: 0.05
  p_downscale: 0.0
  p_shuffle: 0.3
  p_posterize: 0.2
  p_bright_contrast: 0.5
  p_cutout: 0.05
  p_snow: 0.0
  p_rain: 0.0
  p_sun: 0.0
  p_sharpen: 0.3 # 新增锐化

#====
# Training
#====
training:
  project_name: happy_whale
  resume_from: null
  debug: false
  use_wandb: false
  seed: 0
  monitor: val/loss
  monitor_mode: min
  gradient_clip_val: 0.5
  accumulate_grad_batches: 2 # 增加梯度累积以弥补小 BS

  epoch: 20
  batch_size: 8 # 3060 6G 建议从 8 开始测试
  batch_size_test: 32
  num_gpus: 1 # 本地/云端单卡
  num_workers: 4 # CPU 瓶颈时尝试减小此值
  drop_last: true
  use_amp: true


#====
# Optimizer
#====
optimizer:
  type: adamw
  lr: 2e-4
  weight_decay: 0.01
  use_sam: false
  lr_head: 1e-3
  lr_head_species: 1e-3


#====
# Scheduler
#====
scheduler:
  type: cosine_annealing


#====
# Other essential configs
#====
out_dir: ./outputs/effb5_v1
test_model: null
