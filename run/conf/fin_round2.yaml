# @package _global_

hydra:
  job:
    name: happy_whale_fin_effb7
  run:
    dir: ${out_dir}

defaults:
  - dataset: happy_whale
  - optimizer: adamw
  - scheduler: cosine_annealing

  - override hydra/job_logging: default
  - override hydra/hydra_logging: default
  - _self_

dataset:
  pseudo_label_filename: "round2_concat.csv"
  pseudo_label_conf: 0.6
  phase: "train" # 验证模式
  type: happy_whale
  num_classes: 15587
  # Fin 模型关键参数
  crop: backfin
  bbox: null

head:
  type: adaptive_arcface
  m: 0.2
  s: 20.0
  k: 3
  k_species: 3
  head_species: true
  s_species: 30
  use_penalty: true
  margin_coef_id: 0.27126
  margin_power_id: -0.364399
  margin_cons_id: 0.05
  margin_coef_species: 0.226253
  margin_power_species: -0.720133
  margin_cons_species: 0.05
  init: uniform
  init_species: uniform  

pool:
  type: gem
  p: 3
  p_trainable: false

model:
  restore_path: ${test_model}
  base_model: tf_efficientnet_b7_ns
  backbone_class: null
  freeze_backbone: false
  head: ${head}
  output_dim: ${dataset.num_classes}
  output_dim_species: ${dataset.num_species_classes}
  pool: ${pool}
  use_bn: true
  embedding_size: 512
  in_chans: 3
  backbone2: false
  species_embedding_size: -1

preprocessing:
  h_resize_to: 512
  w_resize_to: 512
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

augmentation:
  use_aug: true
  rotate: 15
  translate: 0.25
  shear: 3
  p_affine: 0.5
  crop_scale: 0.9
  crop_l: 0.75
  crop_r: 1.3333333333333333
  p_gray: 0.2
  p_blur: 0.05
  p_noise: 0.05
  p_downscale: 0.0
  p_shuffle: 0.3
  p_posterize: 0.2
  p_bright_contrast: 0.5
  p_cutout: 0.05
  p_snow: 0.0
  p_rain: 0.0
  p_sun: 0.0

forwarder:
  max_epochs: ${training.epoch}
  head: ${head}
  backbone2: ${model.backbone2}
  species_embedding_size: ${model.species_embedding_size}

  tta:
    flip_h: true
    rot90: false
    rot180: false

training:
  project_name: happy_whale_fin_pseudo
  epoch: 30
  batch_size: 20
  batch_size_test: 32
  num_workers: 8
  drop_last: true
  num_gpus: 1
  resume_from: null
  seed: 0
  use_amp: true
  accumulate_grad_batches: 4
  gradient_clip_val: 0.5
  monitor: val/loss
  monitor_mode: min
  debug: false
  use_wandb: true
